My interest in genomic interpretability inspired me to pursue AI interpretability research. I have over 6 years of experience doing empirical research, giving me what I believe to be a usefully atypical skill set for mechanistic interpretability research.

While the vast majority of my coding experience is in developing data analysis pipelines and debugging development environments, I'm fairly comfortable with functional programming paradigms and have designed tools to assist other researchers in data exploration.

I work with Python frequently, though often to implement tools for R.

I have not worked with transformers. My ML experience primarily comes from using autoencoders for automated phenotype detection from 3D images.

Our model organism (Ciona robusta) is a useful developmental biology model because while it is closely related to mouse and human, it has a much smaller genome with fewer redundant gene copies. This simplifies knockout experiments, but the organism remains relatively poorly characterized, requiring much of the genome characterization to rely on inferred orthologs with better characterized species. Integrating these data sets is complicated by the same feature that makes working with C. robusta desirable: each C. robusta gene often maps to multiple mouse or human genes. Much of my work involves creating consensus data sets by integrating inferred orthologs to fill in missing experimental data.


I have extensive bioinformatics experience. Though most of my experience is with high throughput sequencing experiments, I think the skills I can bring to REMIX are best exemplified by my work on image analysis.  

The goal is to automatically detect phenotype clusters from high throughput knockout experiments. There are existing procedures for cell classification, but we're interested in the organism level. The problem is that it is unknown whether any experiment will have a unique phenotypic effect. Though the clustering is straightforward, what makes it difficult is that we want to automate selection of hyperparameters in a way that isn't dependent on crossvalidation using experimenter-assigned labels.

For the initial preprocessing I extracted 114 summary statistics from the images. For the initial data exploration I repurposed a pipeline for single cell RNAseq, but found that the method of dimension reduction used did not account for additive effects of multiple statistics affected by a single phenotype. I improved on this method by using the embedding layer of an autoencoder as the dimension reduction. 

Unsupervised clustering could be performed by using the Leiden algorithm to approximate optimal modularity. This method does not require prior knowledge of expected number of clusters but does require selecting hyperparameters for number of neighbors and resolution. 

My solution was to use prior knowledge of physical protein interactions to select an optimal number of neighbors. Because protein interaction data are sparse for our model, this required generating a protein interaction network using putative orthologs from other species. Automating resolution selection was more complicated due to most objective functions simply monotonically increasing or decreasing with number of clusters. However by combining multiple objective functions I was able to find where one was decreasing faster than the other was increasing.

The result is a model that can assess gene interactions based on their cooccurrence in a cluster in phenotype space.

I'm a bioinformatics researcher working on gene regulation during heart muscle differentiation.  I'm involved in all steps of preprocessing, analysis, modeling, model validation, and data visualization. 
My research involves integrating data from gene expression, chromatin accessibility, and imaging experiments. My career goal is to find new ways of imposing human-readable syntactic structure on messy data, either DNA or neural networks.

I've led several workshops on statistics, programming in R, and HPC environments.
