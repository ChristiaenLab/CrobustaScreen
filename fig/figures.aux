\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{WANG2016232}
\citation{cavanaugh2019akaike}
\citation{PhysRevE.74.016110}
\citation{traag2019louvain}
\HyPL@Entry{0<</S/D>>}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:}{{1}{1}{\relax }{figure.caption.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces MSE and AIC values for each model. A low MSE means the model is better able to recreate the data. A lower AIC indicates adding more embedding dimensions improves MSE sub-logarithmically.\relax }}{1}{table.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Results}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Preprocessing}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dimension Reduction}{1}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Clustering Algorithm}{1}{subsection.2.3}\protected@file@percent }
\newlabel{fig:}{{2a}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:}{{a}{2}{\relax }{figure.caption.2}{}}
\newlabel{fig:}{{2b}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:}{{b}{2}{\relax }{figure.caption.2}{}}
\newlabel{fig:}{{2c}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:}{{c}{2}{\relax }{figure.caption.2}{}}
\newlabel{fig:}{{2d}{2}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:}{{d}{2}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (a) Workflow for embedding selection. Four autoencoders were run in parallel with output embedding dimensions $n \in \{2,3,7,14\}$. We used AIC to select an embedding as described in equation (1). (b) Spearman correlation of input parameters to autoencoder. (c) Embedding values for 2 dimensions by experimental perturbation. (d) Embedding values by experimenter-labeled phenotype.\relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:}{{2}{2}{(a) Workflow for embedding selection. Four autoencoders were run in parallel with output embedding dimensions $n \in \{2,3,7,14\}$. We used AIC to select an embedding as described in equation (1). (b) Spearman correlation of input parameters to autoencoder. (c) Embedding values for 2 dimensions by experimental perturbation. (d) Embedding values by experimenter-labeled phenotype.\relax }{figure.caption.2}{}}
\newlabel{fig:}{{3a}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@fig:}{{a}{3}{\relax }{figure.caption.4}{}}
\newlabel{}{{3b}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@}{{b}{3}{\relax }{figure.caption.4}{}}
\newlabel{}{{3c}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@}{{c}{3}{\relax }{figure.caption.4}{}}
\newlabel{}{{3d}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@}{{d}{3}{\relax }{figure.caption.4}{}}
\newlabel{}{{3e}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@}{{e}{3}{\relax }{figure.caption.4}{}}
\newlabel{}{{3f}{3}{\relax }{figure.caption.4}{}}
\newlabel{sub@}{{f}{3}{\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a) Workflow for clustering embryos. (b) Enrichment scores for $k$ between 3 and 53. (c) Example enrichment score calculation. The $x$-axis gives gene pairs ranked by number of edges in a $k$-NN for a given $k$. The $y$-axis gives the running enrichment score, which is incremented when a pair corresponds to a known interaction and decremented if not. The maximum value gives the output enrichment score, resulting in a higher score the more concentrated known interactions are to the top of the list. (d) 17-NN graph of embryos. (e) Protein interaction network obtained from STRINGdb. (f) Gene interaction network obtained from enrichment of edges in (d) as described in equation (3). The $log2(OR)$ shows the overrepresentation of edges between pairs of conditions compared to a uniform distribution of edges beween conditions as described in equation (4).\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{}{{3}{3}{(a) Workflow for clustering embryos. (b) Enrichment scores for $k$ between 3 and 53. (c) Example enrichment score calculation. The $x$-axis gives gene pairs ranked by number of edges in a $k$-NN for a given $k$. The $y$-axis gives the running enrichment score, which is incremented when a pair corresponds to a known interaction and decremented if not. The maximum value gives the output enrichment score, resulting in a higher score the more concentrated known interactions are to the top of the list. (d) 17-NN graph of embryos. (e) Protein interaction network obtained from STRINGdb. (f) Gene interaction network obtained from enrichment of edges in (d) as described in equation (3). The $log2(OR)$ shows the overrepresentation of edges between pairs of conditions compared to a uniform distribution of edges beween conditions as described in equation (4).\relax }{figure.caption.4}{}}
\newlabel{fig:}{{4a}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@fig:}{{a}{4}{\relax }{figure.caption.5}{}}
\newlabel{}{{4b}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@}{{b}{4}{\relax }{figure.caption.5}{}}
\newlabel{}{{4c}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@}{{c}{4}{\relax }{figure.caption.5}{}}
\newlabel{}{{4d}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@}{{d}{4}{\relax }{figure.caption.5}{}}
\newlabel{}{{4e}{4}{\relax }{figure.caption.5}{}}
\newlabel{sub@}{{e}{4}{\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (a) Workflow for cluster selection. (b) Optimization of $\gamma $ for $k = 17$. $combined\_score$ is the product of $ES$, $recall$, $log2error$, and $mean\_silhouette$. $ES$ is calculated as in Fig.2b-c, but with interactions ranked by ratio of occurrence within clusters to occurrence between clusters. $recall$ is the fraction of known interactions recovered by creating a gene network using partial modularity between conditions (see equation (5)). $log2error$ gives the result of the reduced $k$-NN classifier. $mean\_silhouette$ gives the mean silhouette width as described in equation (6). $/nclust$ shows the effect of $\gamma $ on the number of clusters. (c) Clusters for optimal combined statistic at $k = 17$ and $\gamma = 0.3266$. (d) Hypergeometric test for enrichment of conditions in each cluster as given in equations (7-8). (e) Enrichment test for experimenter-labeled phenotypes in each cluster.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{}{{4}{4}{(a) Workflow for cluster selection. (b) Optimization of $\gamma $ for $k = 17$. $combined\_score$ is the product of $ES$, $recall$, $log2error$, and $mean\_silhouette$. $ES$ is calculated as in Fig.2b-c, but with interactions ranked by ratio of occurrence within clusters to occurrence between clusters. $recall$ is the fraction of known interactions recovered by creating a gene network using partial modularity between conditions (see equation (5)). $log2error$ gives the result of the reduced $k$-NN classifier. $mean\_silhouette$ gives the mean silhouette width as described in equation (6). $/nclust$ shows the effect of $\gamma $ on the number of clusters. (c) Clusters for optimal combined statistic at $k = 17$ and $\gamma = 0.3266$. (d) Hypergeometric test for enrichment of conditions in each cluster as given in equations (7-8). (e) Enrichment test for experimenter-labeled phenotypes in each cluster.\relax }{figure.caption.5}{}}
\citation{10.1093/nar/gkq973}
\citation{subramanian2005gene}
\citation{ROUSSEEUW}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Hyperparameter Selection}{5}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}$k$ Selection}{5}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Ortholog Lookup}{5}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GSEA}{5}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gene Network}{5}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}$\gamma $ Selection}{5}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reduced $k$-NN classifier}{5}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GSEA}{5}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Comparison to Known Protein Interactions}{5}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mean Silhouette Width}{5}{section*.12}\protected@file@percent }
\bibstyle{plain}
\bibdata{refs}
\bibcite{cavanaugh2019akaike}{1}
\bibcite{PhysRevE.74.016110}{2}
\bibcite{ROUSSEEUW}{3}
\bibcite{subramanian2005gene}{4}
\bibcite{10.1093/nar/gkq973}{5}
\bibcite{traag2019louvain}{6}
\bibcite{WANG2016232}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Cluster Characterization}{6}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Hypergeometric Test}{6}{subsubsection.2.5.1}\protected@file@percent }
\gdef \@abspage@last{6}
